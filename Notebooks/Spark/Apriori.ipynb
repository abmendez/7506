{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BroadCast Variables\n",
    "===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tomates', 3, 4), ('papas', 1, 5), ('zanahorias', 4, 6), ('cebollas', 2, 4), ('batatas', 5, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Un hash con los productos y sus nombres, hacemos un broadcast\n",
    "productNames = {1:'papas',2:'cebollas',3:'tomates',4:'zanahorias',5:'batatas',6:'peras',7:'cilantro',8:'apio',9:'morrones',10:'manzanas',11:'naranjas'}\n",
    "bproductNames = sc.broadcast(productNames)\n",
    "\n",
    "# Vamos a suponer que tenemos un RDD de productos por sus IDs identificando ventas de los mismos\n",
    "prodsList = [1,11,1,4,5,11,2,3,4,5,6,4,5,4,3,2,1,11,2,3,4,5,6,4,3,2,1,1]\n",
    "prods = sc.parallelize(prodsList,3)\n",
    "\n",
    "# Buscamos los productos que se vendieron mas de 4 veces\n",
    "popularProds = prods.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).filter(lambda x:x[1]>=4)\n",
    "\n",
    "# Buscamos los nombres\n",
    "popularProds = popularProds.map(lambda x:(bproductNames.value[x[0]],x[0],x[1]))\n",
    "print popularProds.collect()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SON\n",
    "===\n",
    "\n",
    "Version paralelizable de A-Priori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tomate, pepsi\n",
      "-----------------\n",
      "[u'tomate', u'pepsi']\n",
      "-----------------\n",
      "(u'aceitunas', u'queso')\n",
      "-----------------\n",
      "[(u'aceitunas', u'queso'), (u'aceitunas', u'papas', u'salame'), (u'carne', u'coca'), (u'carne', u'papas'), (u'papas', u'queso'), (u'ajo',), (u'queso',), (u'huevos',), (u'carne',), (u'queso', u'salame'), (u'leche',), (u'paales',), (u'cerveza',), (u'salame',), (u'aceitunas', u'queso', u'salame'), (u'papas', u'queso', u'salame'), (u'coca', u'papas'), (u'aceitunas', u'papas'), (u'cerveza', u'paales'), (u'coca',), (u'aceitunas', u'papas', u'queso', u'salame'), (u'aceitunas',), (u'pan',), (u'tomate',), (u'lechuga',), (u'carne', u'coca', u'papas'), (u'aceitunas', u'salame'), (u'aceitunas', u'papas', u'queso'), (u'papas',), (u'papas', u'salame')]\n",
      "=================\n",
      "[((u'huevos',), 14), ((u'queso',), 15), ((u'coca',), 15), ((u'tomate',), 13), ((u'papas',), 28)]\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import re,string\n",
    "import itertools\n",
    "\n",
    "def filterDictionary(d,support):\n",
    "    for item in d.keys():\n",
    "        if d[item]<support:\n",
    "            del(d[item])\n",
    "    return d\n",
    "\n",
    "# N-pass in memory apriori algorithm \n",
    "def apriori(listOfBaskets):\n",
    "    listOfBaskets=list(listOfBaskets)\n",
    "    # This is your parameter\n",
    "    minsupport = 3\n",
    "    frequentItems = dict()\n",
    "    result = dict()\n",
    "    # First scan all items\n",
    "    for basket in listOfBaskets:       \n",
    "        for item in sorted(basket):\n",
    "            if (item,) in frequentItems:\n",
    "                frequentItems[(item,)]+=1\n",
    "            else:\n",
    "                frequentItems[(item,)]=1\n",
    "    # Filter items mantain only individual items with min support\n",
    "    frequentItems = filterDictionary(frequentItems,minsupport)\n",
    "    order = 2\n",
    "    result.update(frequentItems)   \n",
    "    while(frequentItems):\n",
    "        newFrequentItems = dict()\n",
    "        for basket in listOfBaskets:\n",
    "            all_combinations = itertools.combinations(sorted(basket),order)\n",
    "            for combination in all_combinations:\n",
    "                subcombination = itertools.combinations(list(combination),order-1)\n",
    "                # All items must be frequent\n",
    "                isfrequent = True\n",
    "                for item in sorted(subcombination):\n",
    "                    if item not in frequentItems:\n",
    "                        isfrequent = False\n",
    "                        break\n",
    "                # if all subcombinations are freuqnt then add combination\n",
    "                if isfrequent:\n",
    "                    if tuple(sorted(combination)) in newFrequentItems:\n",
    "                        newFrequentItems[tuple(sorted(combination))]+=1\n",
    "                    else:\n",
    "                        newFrequentItems[tuple(sorted(combination))]=1\n",
    "        # Now filter each member of the dictionary by support       \n",
    "        newFrequentItems = filterDictionary(newFrequentItems,minsupport)\n",
    "        frequentItems = newFrequentItems       \n",
    "        result.update(frequentItems)\n",
    "        order = order+1\n",
    "    vector = []\n",
    "    for item in result.keys():\n",
    "        vector.append((item,1))\n",
    "    return vector\n",
    "\n",
    "def filterByList(listaFreqs):\n",
    "    def bar(row):\n",
    "        ret = []\n",
    "        # We have to check if the items in listaFreqs are in this row\n",
    "        for item in listaFreqs:\n",
    "            if set(item).issubset(set(row)):\n",
    "                ret.append((item,1))\n",
    "        return ret\n",
    "    return bar\n",
    "\n",
    "\n",
    "fileName = 'data/apriori/datosapriori.txt'\n",
    "itemsRDD = (sc.textFile(fileName, 4))\n",
    "print itemsRDD.count()\n",
    "print itemsRDD.first()\n",
    "print \"-----------------\"\n",
    "itemsRDD = itemsRDD.map(lambda x:re.sub(r'[^a-zA-Z0-9 ]', '', x)  ).map(lambda x:x.split())\n",
    "print itemsRDD.first()\n",
    "print \"-----------------\"\n",
    "itemsRDD1 = itemsRDD.mapPartitions(apriori).reduceByKey(lambda x,y:x).map(lambda x:x[0])\n",
    "print itemsRDD1.first()\n",
    "print \"-----------------\"\n",
    "# Now we have to map again\n",
    "listaItemsFrecuentes = itemsRDD1.collect()\n",
    "\n",
    "print listaItemsFrecuentes\n",
    "print \"=================\"\n",
    "print itemsRDD.flatMap(filterByList(listaItemsFrecuentes)).reduceByKey(lambda x,y:x+y).filter(lambda x:x[1]>12).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando Pi en Spark\n",
    "-----------------------\n",
    "\n",
    "Because we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.141625\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "NUM_SAMPLES = 10000000\n",
    "def sample(p):\n",
    "    x, y = random(), random()\n",
    "    return 1 if x*x + y*y < 1 else 0\n",
    "\n",
    "count = sc.parallelize(xrange(0, NUM_SAMPLES)).map(sample) \\\n",
    "             .reduce(lambda a, b: a + b)\n",
    "print \"Pi is roughly %f\" % (4.0 * count / NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Monty Hall Problem\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching wins in 66.428000 % of cases\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "NUM_SAMPLES = 100000\n",
    "def sample(p):\n",
    "    prize_door = randrange(3)+1\n",
    "    human_door = randrange(3)+1\n",
    "    if prize_door != human_door:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "count = sc.parallelize(xrange(0, NUM_SAMPLES)).map(sample) \\\n",
    "             .reduce(lambda a, b: a + b)\n",
    "print \"Switching wins in %f\" % (float(count) / NUM_SAMPLES * 100)    + \" % of cases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
