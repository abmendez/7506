{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:00<00:00, 185925.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "ratings_file = '/home/boyto/DataSets/MovieLensResearch/ratings.csv'\n",
    "MAX_RATINGS = 100000\n",
    "\n",
    "G=nx.Graph()\n",
    "i=0\n",
    "with open(ratings_file, 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    line1 = reader.next()\n",
    "    for j in tqdm(range(0,MAX_RATINGS)):\n",
    "        row = reader.next()\n",
    "        #print row            \n",
    "        G.add_edge('u'+row[0],'m'+row[1])\n",
    "        if i>MAX_RATINGS:\n",
    "            break\n",
    "        i = i +1\n",
    "#print(list(G.nodes()))\n",
    "#print(list(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:01<00:00, 80452.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m356', 163), ('m780', 156), ('m296', 149), ('m260', 131), ('m110', 128), ('m318', 127), ('m150', 123), ('m32', 118), ('m480', 118), ('m592', 115)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#starting_node = 'm296' #m296= Pulp Fiction\n",
    "starting_node = 'm1' \n",
    "NUM_WALKS = 100000\n",
    "BETA = 0.8\n",
    "\n",
    "node = starting_node\n",
    "users_table = dict()\n",
    "movies_table = dict()\n",
    "import random\n",
    "import operator\n",
    "\n",
    "for i in tqdm(range(0,NUM_WALKS)):\n",
    "    r_beta = random.random()\n",
    "    if r_beta < BETA:\n",
    "        # Choose a random neighbor\n",
    "        node = random.choice(G.neighbors(node))\n",
    "    else:\n",
    "        # Go back again!\n",
    "        node = starting_node\n",
    "    if node != starting_node:\n",
    "        if node[0]=='u':\n",
    "            if node in users_table:\n",
    "                users_table[node]+=1\n",
    "            else:\n",
    "                users_table[node]=1\n",
    "        else:\n",
    "            if node in movies_table:\n",
    "                movies_table[node]+=1\n",
    "            else:\n",
    "                movies_table[node]=1\n",
    "    #print node\n",
    "movies_table = sorted(movies_table.items(), key=operator.itemgetter(1),reverse=True)\n",
    "users_table = sorted(users_table.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    \n",
    "print movies_table[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think the LSH thingie for movies and users!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_memomask = {}\n",
    "\n",
    "b = 20\n",
    "r = 3\n",
    "NUM_MINHASHES = b*r\n",
    "SHINGLE_LENGTH = 8\n",
    "HASH_SPACE = 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSH_tables = [dict() for i in range(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hash_function(n):\n",
    "  mask = _memomask.get(n)\n",
    "  if mask is None:\n",
    "    random.seed(n)\n",
    "    mask = _memomask[n] = random.getrandbits(32)\n",
    "  def myhash(x):\n",
    "    return hash(x) ^ mask\n",
    "  return myhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shingles(string, length):\n",
    "    return (string[0+i:length+i] for i in range(0, len(string)-length+1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minhashes(string):\n",
    "    minhashes = [float(\"inf\")]*NUM_MINHASHES\n",
    "    for sh in shingles(string, SHINGLE_LENGTH):\n",
    "        for i in range(NUM_MINHASHES):\n",
    "            mh = hash_functions[i](sh) % HASH_SPACE\n",
    "            if mh < minhashes[i]:\n",
    "                minhashes[i] = mh\n",
    "    return minhashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_tweet(line,index):\n",
    "    # Compute minhashes\n",
    "    mh = get_minhashes(line.lower())\n",
    "    # Now group minhashes in b groups of r minhashes each\n",
    "    for i in range(b):\n",
    "        hash_key = ''.join(map(str,(mh[i*r:(i*r)+r])))\n",
    "        if hash_key not in tables[i]:\n",
    "            tables[i][hash_key]=[index]\n",
    "        else:\n",
    "            print all_tweets[index]\n",
    "            print \"collides with:\"\n",
    "            for tweet in tables[i][hash_key]:\n",
    "                print all_tweets[tweet]\n",
    "            tables[i][hash_key].append(index)\n",
    "            print \"---------------------------\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_functions = [get_hash_function(i) for i in range(0,NUM_MINHASHES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A dictionary of Minhashes for every movie\n",
    "movie_mh = dict()\n",
    "discretize_ratings = {'0.0':'b','0.5':'b','1.0':'b','1.5':'b','2.0':'b',\\\n",
    "                      '2.5':'n','3.0':'n','3.5':'n',\\\n",
    "                      '4.0':'g','4.5':'g','5.0':'g'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [01:18<00:00, 12765.24it/s]\n"
     ]
    }
   ],
   "source": [
    "ratings_file = '/home/boyto/DataSets/MovieLensResearch/ratings.csv'\n",
    "MAX_RATINGS = 1000000\n",
    "\n",
    "i=0\n",
    "with open(ratings_file, 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    line1 = reader.next()\n",
    "    for j in tqdm(range(0,MAX_RATINGS)):\n",
    "        row = reader.next()\n",
    "        movieId=row[1]\n",
    "        if not movieId in movie_mh:\n",
    "            movie_mh[movieId] = [float(\"inf\")]*NUM_MINHASHES\n",
    "        string_to_hash = row[0]+discretize_ratings[row[2]]\n",
    "        for i in range(NUM_MINHASHES):\n",
    "            mh = hash_functions[i](string_to_hash) % HASH_SPACE\n",
    "            if mh < movie_mh[movieId][i]:\n",
    "                movie_mh[movieId][i] = mh\n",
    "        if i>MAX_RATINGS:\n",
    "            break\n",
    "        i = i +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13950/13950 [00:01<00:00, 8610.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Collisitions:54257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collisions = 0\n",
    "# Now that we have minhashes for every movie we have to store the movieIds in the LSH table\n",
    "for movie_id in tqdm(movie_mh):\n",
    "    mh = movie_mh[movie_id]\n",
    "    for i in range(b):\n",
    "        hash_key = ''.join(map(str,(mh[i*r:(i*r)+r])))\n",
    "        if hash_key not in LSH_tables[i]:\n",
    "            LSH_tables[i][hash_key]=[movie_id]\n",
    "        else:\n",
    "            LSH_tables[i][hash_key].append(movie_id)\n",
    "            collisions = collisions+1\n",
    "print \"Number of Collisitions:\"+str(collisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('50', 4), ('150', 2), ('593', 2), ('4963', 1), ('3578', 1), ('5445', 1), ('2858', 1), ('1263', 1), ('2762', 1), ('1193', 1), ('1206', 1), ('4886', 1), ('1197', 1), ('356', 1), ('1089', 1), ('47', 1), ('2028', 1), ('293', 1), ('1673', 1)]\n"
     ]
    }
   ],
   "source": [
    "target_movie = '296'\n",
    "#target_movie = '1'\n",
    "mh = movie_mh[target_movie]\n",
    "similar_movies=dict()\n",
    "for i in range(b):\n",
    "        hash_key = ''.join(map(str,(mh[i*r:(i*r)+r])))\n",
    "        if hash_key in LSH_tables[i]:\n",
    "            for candidate in LSH_tables[i][hash_key]:\n",
    "                if candidate != target_movie:\n",
    "                    if candidate in similar_movies:\n",
    "                        similar_movies[candidate]+=1\n",
    "                    else:\n",
    "                        similar_movies[candidate]=1\n",
    "            #similar_movies.append(tables[i][hash_key])\n",
    "similar_movies = sorted(similar_movies.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print similar_movies            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
